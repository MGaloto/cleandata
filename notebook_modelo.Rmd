---
title: "Data Science"
author: "Maximiliano Galoto"
subtitle: "Regresion Lineal"
output:
 prettydoc::html_pretty:
    theme: lumen
    highlight: github
    toc: true
    toc_depth: 2
    math: katex

---


```{css my-header-colors, echo = FALSE}
.page-header {
    background-image: url('https://i.gifer.com/J4o.gif');
    border: solid 1px black;
    border-radius: .3rem;
    background-size: cover;
}

```

```{css , echo = FALSE}

.myimg {
  border: solid 1px black;
}

```


<style type="text/css">

.toc .toc-box {
    padding: 1.5rem;
    background-color: #f5f5f5;
    border: solid 1px #6b6b6b;
    border-radius: .3rem;
}

a {
    color: black;
    text-decoration: none;
    font-weight: bold;
}



.main-content h2, .main-content h3, .main-content h4, .main-content h5, .main-content h6 {
    margin-top: 2rem;
    margin-bottom: 1rem;
    font-weight: 400;
    color: black;
}


.main-content h1 {
    margin-top: 2rem;
    margin-bottom: 1rem;
    font-weight: 750;
    background-image: url('https://i.gifer.com/J4o.gif');
    background-position: center;
    color: white;
    text-align: center;
    border: solid 1px black;
    border-radius: .3rem;
    background-color: #f5f5f5;
} 



h1.title {
  font-size: 58px;
  color: white;
  text-align: center;
}
h3.subtitle { 
    font-size: 28px;
  font-family: "Times New Roman", Times, serif;
  color: white ;
  text-align: center;
}
h4.author { 
    font-size: 24px;
  font-family: "Times New Roman", Times, serif;
  color:white ;
  text-align: center;
}

.main-content table th {
    font-weight: 700;
    background-color: blue;
    color: rgb(255, 255, 255);
}




</style>

<br>
</br>






<div style="text-align: left" class="toc-box">
# 1 - Introduccion
</div>
<div style="text-align: right" class="toc-box">
 <a href="#top">Volver al Inicio</a>
</div>
<br>
</br>

El siguiente trabajo consiste en un análisis preliminar de los datos de la inmobiliaria [Properatti](https://www.properati.com.ar/) luego de una visualización, limpieza y segmentación por CABA [Ver trabajo Aqui](https://rpubs.com/MGaloto/data_wrangling) para luego entrenar un modelo de <span style="color:blue">*Regresión Logística*</span> que nos sirva para predecir el precio en dolares por metro cuadrado. 


<br>
</br>


**_Librerías_**

```{r}

library(reticulate)

Sys.setenv(RETICULATE_PYTHON = 'C:/ProgramData/Anaconda3/python.exe')

use_python('C:/ProgramData/Anaconda3/python.exe')

```




```{python, warning=FALSE}


import pandas as pd
import numpy as np
import plotly.io as pio
import plotly.express as px
import plotly.figure_factory as ff
from time import sleep
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn import metrics
from math import sqrt
from sklearn.model_selection import cross_validate
import warnings
import matplotlib.pyplot as plt
import matplotlib.patches

warnings.filterwarnings('ignore')



data_location = "df_caba.csv"
df_caba = pd.read_csv(data_location, sep=",")
print('El data frame contiene: ',df_caba.shape[0], ' filas y ', df_caba.shape[1], ' columnas.')


```

<div style="text-align: left" class="toc-box">
# 2 - Lectura del Data Set
</div>
<div style="text-align: right" class="toc-box">
 <a href="#top">Volver al Inicio</a>
</div>
<br>
</br>



```{python}

df_caba = df_caba.loc[df_caba['place_name'] != 'Capital Federal']
df_caba.reset_index(drop=True, inplace=True)
df_caba.shape

```


```{python}

df_caba.head(5)

```



```{python}

round(df_caba.isnull().sum() / df_caba.shape[0],2).sort_values(ascending = False)

```

El desvio estandard del precio en dolares por metro cuadrado por zona es el siguiente:

*Se pueden observar dispersiones en los datos que perjudican la estimacion de los parametros de una regresion lineal. La idea principal es homogeneizar los datos lo mejor posible sin alterar la naturaleza de los mismos para generalizar y minimizar los errores.*


```{python}

def getPlotGroupDos(data, number_color):
    x = data.groupby('place_name')['price_usd_per_m2'].std().sort_values(ascending = False).index
    y = data.groupby('place_name')['price_usd_per_m2'].std().sort_values(ascending = False).values
   
    df = pd.DataFrame({'x': x, 'y': y})
    fig = px.bar(df, x=x, y=y,
                title= 'Desvio Standard' + ' m2 ',
                color_discrete_sequence=[px.colors.qualitative.Alphabet[number_color]],
                width=800, height=600,
                template="simple_white"
                )
    return fig.show()
    


getPlotGroupDos(df_caba,  7)

```



Grafico en 3D donde relacionamos las siguientes variables por zona: price_usd_per_m2, surface_covered_in_m2 y ambientes.

```{python}

def plot3d(df, x, y, z, color):
    fig = px.scatter_3d(df, 
                        title = "3D Plot",
                        x = x, 
                        y = y, 
                        z = z, 
                        color = color)
    fig.update_layout(template="plotly_dark",
                      width=800,
                      height=700)
    return fig.show()




```





```{python}

hist_data    = []
group_labels = []
limite_precio = 9000
for i in range(len(df_caba['place_name'].unique())):
    hist_datas = np.array(df_caba.loc[( df_caba['place_name'].isin([df_caba['place_name'].unique()[i]]))&  (df_caba['price_usd_per_m2'] < limite_precio) ].price_usd_per_m2.value_counts().index)
    if len(hist_datas) == 1: continue
    hist_data.append(hist_datas)
    group_labels.append(df_caba['place_name'].unique()[i])


```

Distribucion inicial de los precios en dolares por metro cuadrado:


```{python}

fig = ff.create_distplot(hist_data, group_labels, show_hist=False)
fig.update_layout(title_text='Distribucion del precio en USD por M2')


```




<div style="text-align: left" class="toc-box">
# 3 - Limpieza de Datos 
</div>
<div style="text-align: right" class="toc-box">
 <a href="#top">Volver al Inicio</a>
</div>
<br>
</br>


```{python}

df_caba_model = df_caba[['price_usd_per_m2','property_type','place_name', 'price', 'price_aprox_usd', 'surface_total_in_m2', 'surface_covered_in_m2','rooms', 'ambientes', 'parrilla']]
df_caba_model.head(5)

```




```{python}

df_caba_model['ambientes'] = df_caba_model.apply(lambda x: x['ambientes'] if x['ambientes'] > 0 else x['rooms'], axis = 1)

df_caba_model.drop(columns=['rooms','price_aprox_usd','price'], inplace = True)

round(df_caba_model.isnull().sum() / df_caba_model.shape[0],2).sort_values(ascending = False)
```




```{python}

print('Luego de los drop queda un ',(df_caba_model.dropna().shape[0] / df_caba_model.shape[0]) * 100, '% del Data Set original')

```


```{python}

x1 = np.array(df_caba_model.loc[df_caba_model['place_name'].isin(['Boedo'])].price_usd_per_m2.value_counts().sort_index(ascending = False).index)

hist_data = [x1]
group_labels = ['price_usd_per_m2'] 

fig = ff.create_distplot(hist_data, group_labels, bin_size=400)
fig.show()

```



```{python}
index_drop_surface = df_caba_model.loc[(df_caba_model['place_name'].isin(['Boedo'])) & (df_caba_model['surface_covered_in_m2'].isin([324,350,566,600,800]))].index
index_drop_price_boedo = df_caba_model.loc[(df_caba_model['place_name'].isin(['Boedo'])) & (df_caba_model['price_usd_per_m2'] > 3000)].index
index_drop_price_sancristobal = df_caba_model.loc[(df_caba_model['place_name'].isin(['San Cristobal'])) & (df_caba_model['price_usd_per_m2'] > 3000)].index
df_caba_model.drop(index_drop_surface, inplace=True)
df_caba_model.drop(index_drop_price_boedo, inplace=True)
df_caba_model.drop(index_drop_price_sancristobal, inplace=True)
df_caba_model.reset_index(drop=True, inplace=True)
```






```{python}
index_drop_surface_total = df_caba_model.loc[(df_caba_model['surface_total_in_m2'] > 800)].index
df_caba_model.drop(index_drop_surface_total, inplace=True)
df_caba_model.reset_index(drop=True, inplace=True)


```



```{python}
index_drop_surface_covered = df_caba_model.loc[(df_caba_model['surface_covered_in_m2'] > 800)].index
df_caba_model.drop(index_drop_surface_covered, inplace=True)
df_caba_model.reset_index(drop=True, inplace=True)


```



```{python}
index_drop_ambientes = df_caba_model.loc[(df_caba_model['ambientes'] > 10)].index
df_caba_model.drop(index_drop_ambientes, inplace=True)
df_caba_model.reset_index(drop=True, inplace=True)

```


<div style="text-align: left" class="toc-box">
# 4 - Visualizaciones Post Limpieza
</div>
<div style="text-align: right" class="toc-box">
 <a href="#top">Volver al Inicio</a>
</div>
<br>
</br>



```{python}
getPlotGroupDos(df_caba_model,  3)
```





```{python}

plot3d(df_caba_model, 'price_usd_per_m2', 'surface_total_in_m2', 'ambientes', 'place_name')
```





```{python}
hist_data    = []
group_labels = []

for i in range(len(df_caba_model['place_name'].unique())):
    hist_datas = np.array(df_caba_model.loc[( df_caba_model['place_name'].isin([df_caba_model['place_name'].unique()[i]]))].price_usd_per_m2.value_counts().index)
    if len(hist_datas) == 1: continue
    hist_data.append(hist_datas)
    group_labels.append(df_caba_model['place_name'].unique()[i])

```

```{python}
fig = ff.create_distplot(hist_data, group_labels, show_hist=False)
fig.update_layout(title_text='Distribucion del precio en USD por M2')


```

<div style="text-align: left" class="toc-box">
# 5 - Modelo
</div>
<div style="text-align: right" class="toc-box">
 <a href="#top">Volver al Inicio</a>
</div>
<br>
</br>



```{python}
df_caba_model.dropna(axis=0).shape
```

```{python}

import seaborn as sns
correlation_mat = df_caba_model[['price_usd_per_m2', 'surface_total_in_m2', 'surface_covered_in_m2',
       'ambientes']].corr()
sns.heatmap(correlation_mat, annot = True)
plt.title("Matriz de Correlacion")
plt.show()

```


```{python}
df_caba_model_final = df_caba_model.dropna(axis=0)
df_caba_model_final.reset_index(inplace = True,drop=True)
```

Se crean variable dummies para las features categoricas y se separa el data set en training y set


```{python}

df_caba_model_dummies = pd.get_dummies(df_caba_model_final)

X = df_caba_model_dummies.drop(columns = ["price_usd_per_m2",'surface_total_in_m2'])
y = df_caba_model_dummies[["price_usd_per_m2"]]

Xtrain, Xtest, ytrain, ytest = train_test_split(X,y)


```

Se instancia y entrena el modelo de Linear Regression:

```{python}
modelo = LinearRegression()
modelo.fit(Xtrain,ytrain)


```

Analizo los Betas

```{python}

diccionario = dict(zip(df_caba_model_dummies.drop(columns = ["price_usd_per_m2",'surface_total_in_m2']).columns,[round(value,2) for value in modelo.coef_.tolist()[0]]))

diccionario

```

La presencia de Puerto Madero hace incrementar la variable dependiente

```{python}

diccionario['place_name_Puerto Madero']

```

El **error absoluto medio** (_Mean Absolut Error_ o MAE) es la media del valor absoluto de los errores:

$$ \frac 1n\sum_ {i = 1}^n |y_i-\hat{y}_i| $$


```{python}

pred = modelo.predict(Xtest)

print ('MAE:', metrics.mean_absolute_error(ytest, pred).round(2))
print ('R2:', metrics.r2_score(ytest, pred).round(2))

```

|Modelo||MAE|R2|
|-|-|-|-|
|Regresión Logística Nº1 ||443|0.61|

```{python}

pred_X = modelo.predict(X)
df_caba_model_dummies["Prediccion"] = pred_X
df_caba_model_dummies[["Prediccion", "price_usd_per_m2"]].sort_values(by = 'Prediccion')

```



```{python}


Modelo_cv = LinearRegression()

cv_results = cross_validate(modelo, Xtrain, ytrain, cv=5, scoring=('r2', "neg_mean_absolute_error"))
print(cv_results["test_neg_mean_absolute_error"].mean())
print(cv_results["test_r2"].mean())

```

<div style="text-align: left" class="toc-box">
# 6 - Conclusiones
</div>
<div style="text-align: right" class="toc-box">
 <a href="#top">Volver al Inicio</a>
</div>
<br>
</br>


Luego de generar variables dummies para las features categóricas se estimó un modelo de Regresión Logística dando como resultado un error absoluto medio de 440 dólares por metro cuadrado y un r2 de 0.60.

Estos resultados nos indican que el 60 % de la variabilidad de la variable dependiente esta explicado por las features del modelo y que en promedio el error de estimación del precio en dólares por metro cuadrado es de 440.

Para la validación cruzada se utilizó el promedio de 5 iteraciones dando como resultado valores casi similares a los del modelo tanto en r2 como el MAE.





