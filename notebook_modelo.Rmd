---
title: "Data Science"
author: "Maximiliano Galoto"
subtitle: "Regresion Lineal"
output:
 prettydoc::html_pretty:
    theme: lumen
    highlight: github
    toc: true
    toc_depth: 2
    math: katex

---


```{css my-header-colors, echo = FALSE}
.page-header {
    background-image: url('https://i.gifer.com/J4o.gif');
    border: solid 1px black;
    border-radius: .3rem;
    background-size: cover;
}

```

```{css , echo = FALSE}

.myimg {
  border: solid 1px black;
}

```


<style type="text/css">

.toc .toc-box {
    padding: 1.5rem;
    background-color: #f5f5f5;
    border: solid 1px #6b6b6b;
    border-radius: .3rem;
}

a {
    color: black;
    text-decoration: none;
    font-weight: bold;
}



.main-content h2, .main-content h3, .main-content h4, .main-content h5, .main-content h6 {
    margin-top: 2rem;
    margin-bottom: 1rem;
    font-weight: 400;
    color: black;
}


.main-content h1 {
    margin-top: 2rem;
    margin-bottom: 1rem;
    font-weight: 750;
    background-image: url('https://i.gifer.com/J4o.gif');
    background-position: center;
    color: white;
    text-align: center;
    border: solid 1px black;
    border-radius: .3rem;
    background-color: #f5f5f5;
} 



h1.title {
  font-size: 58px;
  color: white;
  text-align: center;
}
h3.subtitle { 
    font-size: 28px;
  font-family: "Times New Roman", Times, serif;
  color: white ;
  text-align: center;
}
h4.author { 
    font-size: 24px;
  font-family: "Times New Roman", Times, serif;
  color:white ;
  text-align: center;
}

.main-content table th {
    font-weight: 700;
    background-color: blue;
    color: rgb(255, 255, 255);
}




</style>

<br>
</br>






<div style="text-align: left" class="toc-box">
# 1 - Introduccion
</div>
<div style="text-align: right" class="toc-box">
 <a href="#top">Volver al Inicio</a>
</div>
<br>
</br>

El siguiente trabajo consiste en un análisis preliminar de los datos de la inmobiliaria [Properatti](https://www.properati.com.ar/) luego de una visualización, limpieza y segmentación por CABA [(Ver trabajo Aqui)](https://rpubs.com/MGaloto/data_wrangling) para luego entrenar un modelo de <span style="color:blue">*Regresión Logística*</span> que nos sirva para predecir el precio en dolares por metro cuadrado. 


<br>
</br>


**_Librerías_**

Para utilizar código <span style="color:blue">*Python*</span> en R Markdown se usa la librería reticulate.
 
```{r}

library(reticulate)

Sys.setenv(RETICULATE_PYTHON = 'C:/ProgramData/Anaconda3/python.exe')

use_python('C:/ProgramData/Anaconda3/python.exe')

```




```{python, warning=FALSE}


import pandas as pd
import numpy as np
import plotly.io as pio
import plotly.express as px
import plotly.figure_factory as ff
from time import sleep
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn import metrics
from math import sqrt
from sklearn.model_selection import cross_validate
import warnings
import matplotlib.pyplot as plt
import matplotlib.patches

warnings.filterwarnings('ignore')



data_location = "df_caba.csv"
df_caba = pd.read_csv(data_location, sep=",")
print('El data frame contiene: ',df_caba.shape[0], ' filas y ', df_caba.shape[1], ' columnas.')


```

<div style="text-align: left" class="toc-box">
# 2 - Lectura del Data Set
</div>
<div style="text-align: right" class="toc-box">
 <a href="#top">Volver al Inicio</a>
</div>
<br>
</br>



```{python}

df_caba = df_caba.loc[df_caba['place_name'] != 'Capital Federal']
df_caba.reset_index(drop=True, inplace=True)
df_caba.shape

```


```{python}

df_caba.head(5)

```



```{python}

round(df_caba.isnull().sum() / df_caba.shape[0],2).sort_values(ascending = False)

```


*Se pueden observar dispersiones en los datos que perjudican la estimación de los parámetros de una regresión lineal. La idea principal es homogeneizar los datos lo mejor posible sin alterar la naturaleza de los mismos para generalizar y minimizar los errores.*


```{python}

def getPlotGroupDos(data, number_color):
    x = data.groupby('place_name')['price_usd_per_m2'].std().sort_values(ascending = False).index
    y = data.groupby('place_name')['price_usd_per_m2'].std().sort_values(ascending = False).values
   
    df = pd.DataFrame({'x': x, 'y': y})
    fig = px.bar(df, x=x, y=y,
                title= 'Desvio Standard' + ' m2 ',
                color_discrete_sequence=[px.colors.qualitative.Alphabet[number_color]],
                width=800, height=600,
                template="simple_white"
                )
    return fig.show()
    


getPlotGroupDos(df_caba,  7)

```




```{python}
def plot3d(df, x, y, z, color):
    fig = px.scatter_3d(df, 
                        title = "3D Plot",
                        x = x, 
                        y = y, 
                        z = z, 
                        color = color)
    fig.update_layout(template="plotly_dark",
                      width=800,
                      height=700)
    return fig.show()
```





```{python}
hist_data    = []
group_labels = []
limite_precio = 9000
for i in range(len(df_caba['place_name'].unique())):
    hist_datas = np.array(df_caba.loc[( df_caba['place_name'].isin([df_caba['place_name'].unique()[i]]))&  (df_caba['price_usd_per_m2'] < limite_precio) ].price_usd_per_m2.value_counts().index)
    if len(hist_datas) == 1: continue
    hist_data.append(hist_datas)
    group_labels.append(df_caba['place_name'].unique()[i])
```

Distribucion inicial de los precios en dolares por metro cuadrado:


```{python}
fig = ff.create_distplot(hist_data, group_labels, show_hist=False)
fig.update_layout(title_text='Distribucion del precio en USD por M2')
```




<div style="text-align: left" class="toc-box">
# 3 - Limpieza de Datos 
</div>
<div style="text-align: right" class="toc-box">
 <a href="#top">Volver al Inicio</a>
</div>
<br>
</br>


```{python}
df_caba_model = df_caba[['price_usd_per_m2','property_type','place_name', 'price', 'price_aprox_usd', 'surface_total_in_m2', 'surface_covered_in_m2','rooms', 'ambientes', 'parrilla']]
df_caba_model.head(5)
```




```{python}
df_caba_model['ambientes'] = df_caba_model.apply(lambda x: x['ambientes'] if x['ambientes'] > 0 else x['rooms'], axis = 1)

df_caba_model.drop(columns=['rooms','price_aprox_usd','price'], inplace = True)

round(df_caba_model.isnull().sum() / df_caba_model.shape[0],2).sort_values(ascending = False)
```




```{python}
print('Luego de los drop queda un ',(df_caba_model.dropna().shape[0] / df_caba_model.shape[0]) * 100, '% del Data Set original')
```


```{python}
x1 = np.array(df_caba_model.loc[df_caba_model['place_name'].isin(['Boedo'])].price_usd_per_m2.value_counts().sort_index(ascending = False).index)

hist_data = [x1]
group_labels = ['price_usd_per_m2'] 

fig = ff.create_distplot(hist_data, group_labels, bin_size=400)
fig.show()
```



```{python}
index_drop_surface = df_caba_model.loc[(df_caba_model['place_name'].isin(['Boedo'])) & (df_caba_model['surface_covered_in_m2'].isin([324,350,566,600,800]))].index
index_drop_price_boedo = df_caba_model.loc[(df_caba_model['place_name'].isin(['Boedo'])) & (df_caba_model['price_usd_per_m2'] > 3000)].index
index_drop_price_sancristobal = df_caba_model.loc[(df_caba_model['place_name'].isin(['San Cristobal'])) & (df_caba_model['price_usd_per_m2'] > 3000)].index
df_caba_model.drop(index_drop_surface, inplace=True)
df_caba_model.drop(index_drop_price_boedo, inplace=True)
df_caba_model.drop(index_drop_price_sancristobal, inplace=True)
df_caba_model.reset_index(drop=True, inplace=True)
```






```{python}
index_drop_surface_total = df_caba_model.loc[(df_caba_model['surface_total_in_m2'] > 800)].index
df_caba_model.drop(index_drop_surface_total, inplace=True)
df_caba_model.reset_index(drop=True, inplace=True)
```



```{python}
index_drop_surface_covered = df_caba_model.loc[(df_caba_model['surface_covered_in_m2'] > 800)].index
df_caba_model.drop(index_drop_surface_covered, inplace=True)
df_caba_model.reset_index(drop=True, inplace=True)
```



```{python}
index_drop_ambientes = df_caba_model.loc[(df_caba_model['ambientes'] > 10)].index
df_caba_model.drop(index_drop_ambientes, inplace=True)
df_caba_model.reset_index(drop=True, inplace=True)
```


<div style="text-align: left" class="toc-box">
# 4 - Visualizaciones Post Limpieza
</div>
<div style="text-align: right" class="toc-box">
 <a href="#top">Volver al Inicio</a>
</div>
<br>
</br>



```{python}
getPlotGroupDos(df_caba_model,  3)
```





```{python}
plot3d(df_caba_model, 'price_usd_per_m2', 'surface_total_in_m2', 'ambientes', 'place_name')
```





```{python}
hist_data    = []
group_labels = []

for i in range(len(df_caba_model['place_name'].unique())):
    hist_datas = np.array(df_caba_model.loc[( df_caba_model['place_name'].isin([df_caba_model['place_name'].unique()[i]]))].price_usd_per_m2.value_counts().index)
    if len(hist_datas) == 1: continue
    hist_data.append(hist_datas)
    group_labels.append(df_caba_model['place_name'].unique()[i])

```

```{python}
fig = ff.create_distplot(hist_data, group_labels, show_hist=False)
fig.update_layout(title_text='Distribucion del precio en USD por M2')
```

<div style="text-align: left" class="toc-box">
# 5 - Variables Dummies
</div>
<div style="text-align: right" class="toc-box">
 <a href="#top">Volver al Inicio</a>
</div>
<br>
</br>

El primer paso para estimar los parámetros del modelo es eliminar todas las filas que contienen al menos un dato nulo ya que el modelo no nos permite tener este tipo de valores.

En el segundo paso se seleccionan solo las observaciones que son departamentos para el modelo y se eliminan las filas de zonas que tienen pocas observaciones.

```{python}
df_caba_model.dropna(axis=0, inplace = True)
df_caba_model = df_caba_model.loc[df_caba_model['property_type'] == 'apartment']
```

```{python}
df_caba_model.place_name.value_counts(ascending=True)[0:10].index
```

```{python}
values = ['Catalinas', 'Villa Real', 'Villa Soldati', 'Velez Sarsfield',
       'Parque Chas', 'Versalles', 'Pompeya', 'Villa Santa Rita',
       'Parque Avellaneda', 'Agronomía']
df_caba_model = df_caba_model[~df_caba_model.place_name.isin(values)]
```

La matriz de correlación nos sirve para ver si hay variables que se correlacionan para poder evitar multicolinealidad en el modelo:

```{python}

import seaborn as sns
correlation_mat = df_caba_model[['price_usd_per_m2', 'surface_total_in_m2', 'surface_covered_in_m2',
       'ambientes']].corr()
sns.heatmap(correlation_mat, annot = True)
plt.title("Matriz de Correlacion")
plt.show()

```


```{python}
df_caba_model_final = df_caba_model.dropna(axis=0)
df_caba_model_final.reset_index(inplace = True,drop=True)
```



Se crean variable dummies para las features categóricas y se separa el data set en training y set


```{python}
df_caba_model_dummies = pd.get_dummies(df_caba_model_final, drop_first = True)
```


<div style="text-align: left" class="toc-box">
# 6 - Modelo
</div>
<div style="text-align: right" class="toc-box">
 <a href="#top">Volver al Inicio</a>
</div>
<br>
</br>



```{python}
X = df_caba_model_dummies.drop(columns = ["price_usd_per_m2",'surface_total_in_m2'])
y = df_caba_model_dummies[["price_usd_per_m2"]]

Xtrain, Xtest, ytrain, ytest = train_test_split(X,y)
```

Se instancia y entrena el modelo de Linear Regression:

```{python}
modelo = LinearRegression()
modelo.fit(Xtrain,ytrain)
```

Analizo los Betas

```{python}
diccionario = dict(zip(df_caba_model_dummies.drop(columns = ["price_usd_per_m2",'surface_total_in_m2']).columns,[round(value,2) for value in modelo.coef_.tolist()[0]]))
```

La presencia de Puerto Madero hace incrementar la variable dependiente

```{python}

diccionario['place_name_Puerto Madero']

```

Para evaluar el modelo se utiliza el MAE, la validación cruzada y el r2. El MAE es el elegido ya que nos da un valor robusto para nuestro analisis, el valor absoluto del error promedio del modelo

El **error absoluto medio** (_Mean Absolut Error_ o MAE) es la media del valor absoluto de los errores:

$$ \frac 1n\sum_ {i = 1}^n |y_i-\hat{y}_i| $$


```{python}
pred = modelo.predict(Xtest)

from sklearn.model_selection import cross_validate

cv_results = cross_validate(modelo, Xtrain, ytrain, cv=5, scoring=('r2', "neg_mean_absolute_error"))

print ('MAE:', metrics.mean_absolute_error(ytest, pred).round(2))
print ('R2:', metrics.r2_score(ytest, pred).round(2))
print ('MAE CV:', cv_results["test_neg_mean_absolute_error"].mean().round(2)*-1)
print ('R2 CV:', cv_results["test_r2"].mean().round(2))
```

+ El modelo arroja los siguientes resultados:


|Modelo||MAE|R2|MAE CV|R2 CV|
|-|-|-|-|-|-|
|Regresión Logística Nº1 ||434|0.60|432|0.59|

```{python}
pred_X = modelo.predict(X)
df_caba_model_dummies["Prediccion"] = pred_X
df_caba_model_dummies[["Prediccion", "price_usd_per_m2"]].sort_values(by = 'Prediccion').head(5)
```



<div style="text-align: left" class="toc-box">
# 7 - Conclusiones
</div>
<div style="text-align: right" class="toc-box">
 <a href="#top">Volver al Inicio</a>
</div>
<br>
</br>

Se realizo una ultima limpieza del set de datos seleccionando solo los departamentos y las localidades que tienen mas de 20 observaciones. El modelo arroja resultados interesantes teniendo en cuenta las dificultades al momento de tratar valores atípicos ya que estos mismos son perjudiciales para un modelo de regresión lineal múltiple que busca hacer una generalización lo mejor posible para los datos.

Las pruebas de validación cruzada son consistentes con el primer resultado re R2 y error cuadrático medio. Se puede concluir que es un modelo en donde las variables independientes explican un 60 % de la variabilidad del precio en dolares por metro cuadrado y el error promedio de estimación es de 430 Usd el metro cuadrado.




